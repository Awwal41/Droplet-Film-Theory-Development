{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1EWx13AGiaPq"
      },
      "outputs": [],
      "source": [
        "# Model agnostic \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from dft_utils import DataMstr  # run pip install . in home directory if modulle DNE\n",
        "\n",
        "# Model specific \n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data preparation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = \"/Users/deanmsweeney/Documents/UM-Google Drive/Classes/ChE 696/project/symbolic-machine-learning-liquidloading/datasets/processed_well_data.csv\"\n",
        "drop_cols = ['Dia', 'Dev(deg)','Area (m2)', 'z','GasDens','LiquidDens', 'P/T','friction_factor', 'critical_film_thickness', 'Test status']\n",
        "D = DataMstr(path=path, drop_cols=drop_cols)\n",
        "D.split_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9397504456327986"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# define xgboost pipeline\n",
        "def xgboost():\n",
        "   \n",
        "   # list hyperparameters \n",
        "\n",
        "    xgb = XGBRegressor(\n",
        "        objective=\"reg:squarederror\",\n",
        "        n_estimators=200,\n",
        "        learning_rate=0.1,\n",
        "        random_state=42,\n",
        "        importance_type=\"gain\"           # use split‑gain as importance metric\n",
        "        )\n",
        "\n",
        "    # 2) Wrap it in SelectFromModel\n",
        "    selector = SelectFromModel(\n",
        "        estimator=xgb,\n",
        "        threshold=\"mean\",                # keep features with importance ≥ mean importance\n",
        "        prefit=False                     # will fit selector inside the pipeline\n",
        "    )\n",
        "\n",
        "    # 3) Build a pipeline\n",
        "    pipe = Pipeline([\n",
        "        (\"feature_sel\", selector),\n",
        "        (\"model\",       xgb),\n",
        "    ])\n",
        "\n",
        "    avg_acc = D.custom_CV(model=pipe, k_folds=5) # activates for loop for k-fold cross validation \n",
        "\n",
        "    return avg_acc\n",
        "\n",
        "xgboost()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def optimize_sindy_hyperparameters(X_train, y_train, gsflow_train, loading_train, param_grid):\n",
        "    best_score = -1\n",
        "    best_params = None\n",
        "    \n",
        "    X_train = np.array(X_train)\n",
        "    y_train = np.array(y_train).flatten()\n",
        "    gsflow_train = np.array(gsflow_train)\n",
        "    loading_train = np.array(loading_train)\n",
        "    \n",
        "    print(\"Begin training and hyperparameter optimization...\")\n",
        "    for alpha in param_grid['alpha']:\n",
        "        for threshold in param_grid['threshold']:\n",
        "            for interval in param_grid['interval']:\n",
        "                for n in param_grid['n']:\n",
        "                    for f in param_grid['f']:\n",
        "                        score = evaluate_sindy((alpha, threshold, interval, n, f), \n",
        "                                            X_train, y_train, gsflow_train, loading_train)\n",
        "                    \n",
        "                    if score > best_score:\n",
        "                        best_score = score\n",
        "                        best_params = {'alpha': alpha, 'threshold': threshold, 'interval': interval, 'n': n}\n",
        "    \n",
        "    return best_params, best_score"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
