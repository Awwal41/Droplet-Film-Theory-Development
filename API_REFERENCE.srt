API Reference
Droplet-Film Theory Development
Scripts 2.0

Technical Documentation
This file contains detailed technical specifications
for all classes, methods, and parameters in the DFT implementation.
Use this for development and advanced usage.

DFT Class - Core Physics Model
Class: dft_model.DFT
Purpose: Implements the Droplet-Film Theory physics model
for predicting critical flow rates in gas wells.

DFT Class Constructor
__init__(self, seed=42, feature_tol=1.0, dev_tol=1e-3, multiple_dev_policy="max")

Parameters:
- seed: Random seed for reproducibility (int)
- feature_tol: Feature distance threshold (float)
- dev_tol: Deviation tolerance for matching (float)
- multiple_dev_policy: Policy for multiple matches (str)

DFT Class Methods
Methods:
- fit(X, y): Train the model on data
- predict(X, dev_train=None, alpha_strategy='enhanced_dev_based'): Make predictions
- _eq(params, X): Compute predicted values using physics equation
- _loss(params): Compute loss function for optimization

DFT.fit() Method
fit(self, X: np.ndarray, y: np.ndarray) -> self

Parameters:
- X: Input features array (n_samples, 10)
- y: Target values array (n_samples,)

Returns: self (fitted model)

DFT.fit() Implementation Details
- Uses Powell optimization method
- Optimizes 5 global parameters (p1-p5)
- Optimizes alpha parameters for each training sample
- Sets bounds: p1-p5 unbounded, alpha in [0, 1]
- Maximum iterations: 5000, maximum function calls: 10000

DFT.predict() Method
predict(self, X, dev_train=None, alpha_strategy='enhanced_dev_based') -> np.ndarray

Parameters:
- X: New input data (n_samples, 10)
- dev_train: Training deviation angles (optional)
- alpha_strategy: Alpha assignment strategy (must be 'enhanced_dev_based')

Returns: Predicted values array (n_samples,)

DFT.predict() Alpha Assignment Strategy
Three strategies based on well deviation angle:

1. Dev < 10°: Regular deviation-based matching
   - Find samples within dev_tol
   - Apply multiple_dev_policy if multiple matches

2. 10° ≤ Dev < 20°: Minimum alpha strategy
   - Find samples within dev_tol
   - Use minimum alpha among matches

3. Dev ≥ 20°: Full-feature matching
   - Compute Euclidean distance to all training samples
   - Use closest sample's alpha if distance < feature_tol
   - Otherwise use mean training alpha

DFT._eq() Method - Physics Equation
_eq(self, params, X) -> np.ndarray

Implements the core physics equation:
Qcr = p1 * sqrt(|term1 * alpha + (1-alpha) * term2| * (1/z) * (P/T))

Where:
- term1: Film reversal effects
- term2: Droplet effects
- alpha: Balance parameter (0-1)

Physics Equation Components
term1 = (2 * g * Dia * (1 - 3*(Dia/h_cr) + 3*(Dia/h_cr)²) * 
         (ρ_l - ρ_g) * cos(Dev) / (f * ρ_g)) * p4

term2 = |sin(p5 * Dev)|^p3 * ((ρ_l - ρ_g)^p2 / ρ_g²)

Parameters p1-p5 are global optimization parameters.

ChiefBldr Class - Data Management
Class: utils.ChiefBldr
Purpose: Handles dataset splitting, preprocessing, 
model training, and evaluation.

ChiefBldr Constructor
__init__(self, path: str, seed: int=42, drop_cols=None, 
         includ_cols=None, test_size: float=0.20, scale: bool=False)

Parameters:
- path: Path to dataset file (str)
- seed: Random seed (int)
- drop_cols: Columns to exclude (List[str] or None)
- includ_cols: Columns to include (List[str] or None)
- test_size: Fraction for test set (float)
- scale: Whether to scale features (bool)

ChiefBldr Attributes
After initialization, the following attributes are available:
- X: Full feature matrix (n_samples, n_features)
- y: Target values (n_samples,)
- X_train, X_test: Split training and test features
- y_train, y_test: Split training and test targets
- feature_names: List of feature column names

ChiefBldr.evolv_model() Method
evolv_model(self, build_model: Callable, hparam_grid: Dict, 
            k_folds: int=5) -> Any

Parameters:
- build_model: Function that creates model from hyperparameters
- hparam_grid: Dictionary of hyperparameter lists to try
- k_folds: Number of cross-validation folds (int)

Returns: Best trained model

ChiefBldr.evolv_model() Implementation
- Performs grid search over hyperparameter combinations
- Uses k-fold cross-validation for each combination
- Selects best model based on validation performance
- Stores training and test predictions
- Computes performance metrics (MSE, R²)

ChiefBldr Performance Metrics
After training, the following metrics are available:
- loss: Mean squared error on training data
- r2_score: R-squared correlation coefficient
- y_train_pred: Training predictions
- y_test_pred: Test predictions

QLatticeWrapper Class - Symbolic Regression
Class: utils.QLatticeWrapper
Purpose: Provides interface to Feyn QLattice
for automated symbolic regression.

QLatticeWrapper Constructor
__init__(self, feature_tags: List, output_tag: int="Qcr", 
         seed: int=42, max_complexity: int=10, 
         n_epochs: int=10, criterion: str="bic")

Parameters:
- feature_tags: List of feature names (List[str])
- output_tag: Target variable name (str)
- seed: Random seed (int)
- max_complexity: Maximum model complexity (int)
- n_epochs: Number of training epochs (int)
- criterion: Model selection criterion (str)

QLatticeWrapper Methods
Methods:
- fit(X, y): Train the QLattice model
- predict(X): Make predictions
- express(): Get symbolic expression

QLatticeWrapper.fit() Method
fit(self, X: np.ndarray, y: np.ndarray) -> self

Parameters:
- X: Input features array (n_samples, n_features)
- y: Target values array (n_samples,)

Returns: self (fitted model)

QLatticeWrapper.predict() Method
predict(self, X: np.ndarray) -> np.ndarray

Parameters:
- X: Input features array (n_samples, n_features)

Returns: Predicted values array (n_samples,)

QLatticeWrapper.express() Method
express(self) -> sympy.Expr

Returns: Symbolic expression of the trained model
in SymPy format for mathematical analysis.

Data Format Requirements
Input CSV must contain exactly these columns:
1. Dia: Well diameter (meters)
2. Dev(deg): Well deviation angle (degrees)
3. Area (m2): Cross-sectional area (square meters)
4. z: Elevation change (meters)
5. GasDens: Gas density (kg/m³)
6. LiquidDens: Liquid density (kg/m³)
7. g (m/s2): Gravitational acceleration (m/s²)
8. P/T: Pressure/Temperature ratio (Pa/K)
9. friction_factor: Friction factor (dimensionless)
10. critical_film_thickness: Critical film thickness (meters)

Data Preprocessing
ChiefBldr automatically:
- Loads CSV data using pandas
- Splits into training and test sets
- Optionally scales features (if scale=True)
- Validates column names
- Handles missing values

Model Training Workflow
1. Data Loading: ChiefBldr loads and preprocesses data
2. Model Definition: Define DFT model with parameters
3. Hyperparameter Grid: Define search space
4. Cross-Validation: k-fold CV for each combination
5. Model Selection: Best model based on validation performance
6. Final Training: Train best model on full training set

Hyperparameter Optimization
Supported hyperparameters:
- dev_tol: [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]
- feature_tol: [0.1, 0.5, 1.0, 2.0, 5.0, 10.0]
- multiple_dev_policy: ["max", "min", "mean", "median"]

Performance Metrics
Available metrics:
- Mean Squared Error (MSE): Average squared prediction error
- R-squared (R²): Proportion of variance explained
- Cross-validation scores: Performance across folds
- Training vs Test performance: Overfitting detection

Model Persistence
Models can be saved and loaded using:
- pickle: Standard Python serialization
- joblib: Alternative for large models
- JSON: For model parameters only
- HDF5: For large datasets and models

Error Handling
Built-in error handling for:
- Invalid input data
- Missing required columns
- Optimization failures
- Memory issues
- Import errors

Memory and Performance
- Memory usage scales with dataset size
- Training time scales with hyperparameter grid size
- Use data sampling for large datasets during development
- Consider parallel processing for large hyperparameter searches

Scalability Considerations
- DFT model: Scales linearly with number of samples
- ChiefBldr: Memory scales with dataset size
- QLattice: Training time scales with complexity and epochs
- Cross-validation: Time scales with k_folds

Integration Capabilities
- Scikit-learn compatible interface
- Pandas DataFrame support
- NumPy array compatibility
- Matplotlib/Seaborn visualization
- Jupyter notebook integration

Development and Testing
- Type hints for all functions
- Comprehensive docstrings
- Unit test framework support
- Error message localization
- Logging capabilities

Future API Extensions
Planned additions:
- Additional physics models
- Ensemble methods
- Real-time prediction
- API endpoints
- Cloud deployment support

End of API Reference
Return to MAIN_DOCUMENTATION.srt
for overview and other documentation sections
