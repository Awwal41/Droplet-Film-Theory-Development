{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "1EWx13AGiaPq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pysindy import SINDy\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from pysindy.optimizers import STLSQ\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "BFytgP62-4Yi",
        "outputId": "a7f551c0-b56b-460b-96a2-6ecf7a4102bd"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"processed_well_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huCGnlkgLqLW",
        "outputId": "bd6e6575-1ff3-4c6b-c13a-3afc0b788201"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Well no                    0\n",
            "Dia                        0\n",
            "Dev(deg)                   0\n",
            "LiquidFlowrate             0\n",
            "Gasflowrate                0\n",
            "Area (m2)                  0\n",
            "z                          0\n",
            "GasDens                    0\n",
            "Condesnate Presence        0\n",
            "Water presence             0\n",
            "LiquidDens                 0\n",
            "GasVis                     0\n",
            "LiqVis                     0\n",
            "g (m/s2)                   0\n",
            "Test Vg                    0\n",
            "P/T                        0\n",
            "Test status                0\n",
            "Vsg                        0\n",
            "Vsl                        0\n",
            "Rel                        0\n",
            "Reg                        0\n",
            "film thickness             0\n",
            "d(0,90)                    0\n",
            "d(15,90)                   0\n",
            "d(30,90)                   0\n",
            "d(45,90)                   0\n",
            "d(60,90)                   0\n",
            "d(90,90)                   0\n",
            "d(120,90)                  0\n",
            "d(150,90)                  0\n",
            "d(180,90)                  0\n",
            "d(210,90)                  0\n",
            "d(270,90)                  0\n",
            "d(360,90)                  0\n",
            "friction_factor            0\n",
            "critical_film_thickness    0\n",
            "Qcr                        0\n",
            "Î”Q                         0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data preparation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split features\n",
        "X = df[['Dia', 'Dev(deg)','Area (m2)', 'z','GasDens','LiquidDens', 'P/T','friction_factor', 'critical_film_thickness']]\n",
        "y = df['Qcr']\n",
        "gsflow = df['Gasflowrate']  # This is your additional target for classification metrics\n",
        "\n",
        "# load class labels: loaded/unloaded/near loaded\n",
        "loading_class = df['Test status'].apply(\n",
        "    lambda x: -1 if x == 'Unloaded' else (0 if x == 'Near L.U' else 1)).to_numpy()\n",
        "\n",
        "# Perform the train-test split, making sure to split all targets simultaneously\n",
        "X_train, X_test, y_train, y_test, gsflow_train, gsflow_test, loading_train, loading_test = train_test_split(\n",
        "    X, y, gsflow, loading_class, test_size=0.20, random_state=42, stratify=loading_class\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "For final evaluation of the model, we need designate test data and normalize to all training data\n",
        "\"\"\"\n",
        "# Scale your features and continuous target (Qcr)\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "X_scaled = scaler_X.transform(X)\n",
        "\n",
        "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# t_train is just an index array for plotting\n",
        "t_train = np.arange(len(y_train_scaled))\n",
        "\n",
        "#convert to a numpy array and store test data \n",
        "loading_test = np.array(loading_test)\n",
        "gsflow_test = np.array(gsflow_test)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [],
      "source": [
        "# accuracy metric and confusion matrix \n",
        "def calculate_accuracy(y_pred, gsflow, loading_actual, interval):\n",
        "    loading_pred = np.where(y_pred > gsflow + interval, 1, \n",
        "                          np.where(y_pred < gsflow - interval, -1, 0))\n",
        "    return accuracy_score(loading_actual, loading_pred), confusion_matrix(loading_actual, loading_pred,  labels=[-1, 0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [],
      "source": [
        "# K-fold cross validation\n",
        "\"\"\"\n",
        "def evaluate_sindy(params, X, y, gsflow, loading_class, cv_splits=5):\n",
        "    alpha, threshold, interval = params\n",
        "    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
        "    acc_scores = []\n",
        "\"\"\"\n",
        "from sklearn.model_selection import StratifiedKFold  # <-- Replace KFold with this\n",
        "\n",
        "def evaluate_sindy(params, X, y, gsflow, loading_class, cv_splits=5):\n",
        "    alpha, threshold, interval = params\n",
        "    \n",
        "    # Use StratifiedKFold to preserve class balance in splits\n",
        "    kf = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    acc_scores = []\n",
        "    \n",
        "    for train_idx, val_idx in kf.split(X, loading_class):  # Using validation split from training data\n",
        "        # divide into trianing/validation sets\n",
        "        X_train_cv, X_val_cv = X[train_idx], X[val_idx]\n",
        "        y_train_cv, y_val_cv = y[train_idx], y[val_idx]\n",
        "        gsflow_val_cv = gsflow[val_idx]\n",
        "        loading_val_cv = loading_class[val_idx]\n",
        "        \n",
        "        scaler_X = StandardScaler()\n",
        "        X_train_cv_scaled = scaler_X.fit_transform(X_train_cv)\n",
        "        X_val_cv_scaled = scaler_X.transform(X_val_cv)\n",
        "        \n",
        "        scaler_y = StandardScaler()\n",
        "        y_train_cv_scaled = scaler_y.fit_transform(y_train_cv.reshape(-1, 1))\n",
        "        \n",
        "        # Define optimizer for SINDy\n",
        "        optimizer = STLSQ(\n",
        "            alpha=alpha,\n",
        "            threshold=threshold,\n",
        "            max_iter=10000,\n",
        "            normalize_columns=True\n",
        "        )\n",
        "        \n",
        "        # Train model\n",
        "        model = SINDy(optimizer=optimizer)\n",
        "        model.fit(X_train_cv_scaled, t=np.arange(len(y_train_cv_scaled)), \n",
        "                 x_dot=y_train_cv_scaled)\n",
        "        \n",
        "        # Compute performance on validation set \n",
        "        y_val_pred_scaled = model.predict(X_val_cv_scaled)\n",
        "        y_val_pred_cv = scaler_y.inverse_transform(y_val_pred_scaled).flatten()\n",
        "        \n",
        "        acc, cm = calculate_accuracy(y_val_pred_cv, gsflow_val_cv, loading_val_cv, interval)\n",
        "        acc_scores.append(acc)\n",
        "    \n",
        "    return np.mean(acc_scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def optimize_sindy_hyperparameters(X_train, y_train, gsflow_train, loading_train, param_grid):\n",
        "    best_score = -1\n",
        "    best_params = None\n",
        "    \n",
        "    X_train = np.array(X_train)\n",
        "    y_train = np.array(y_train).flatten()\n",
        "    gsflow_train = np.array(gsflow_train)\n",
        "    loading_train = np.array(loading_train)\n",
        "    \n",
        "    print(\"Begin training and hyperparameter optimization...\")\n",
        "    for alpha in param_grid['alpha']:\n",
        "        for threshold in param_grid['threshold']:\n",
        "            for interval in param_grid['interval']:\n",
        "                score = evaluate_sindy((alpha, threshold, interval), \n",
        "                                     X_train, y_train, gsflow_train, loading_train)\n",
        "                \n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_params = {'alpha': alpha, 'threshold': threshold, 'interval': interval}\n",
        "    \n",
        "    return best_params, best_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Begin training and hyperparameter optimization...\n",
            "\n",
            "Best parameters found:\n",
            "{'alpha': 0.5994842503189409, 'threshold': 0.12915496650148828, 'interval': 0.0}\n",
            "Best CV accuracy: 70.45%\n",
            "\n",
            "=== Final Model Performance ===\n",
            "(x0)' = 3086689209694.944 1 + 107.192 x0 + -3565097616966.648 x1 + 1.868 x2 + 0.192 x3 + 1.971 x4 + -3220096138240.641 x5 + 0.378 x6 + 180.062 x7 + -137.560 x8 + -0.318 x0^2 + 1.016 x0 x1 + -0.347 x0 x2 + -0.024 x0 x3 + 2.315 x0 x4 + -0.775 x0 x5 + 73.950 x0 x7 + -0.285 x0 x8 + -2.973 x1 x2 + 3719181391151.834 x1 x5 + -0.527 x1 x6 + -0.033 x1 x8 + 1.095 x2^2 + -4.298 x2 x4 + 0.037 x2 x5 + -0.056 x2 x6 + 2.432 x2 x7 + -0.077 x2 x8 + -0.009 x3^2 + 1.065 x3 x4 + 0.473 x3 x6 + 0.110 x3 x8 + -0.556 x4 x5 + -0.627 x4 x6 + 4.272 x4 x7 + 0.180 x4 x8 + -0.338 x5^2 + -0.362 x5 x6 + -1.832 x5 x7 + 1.268 x5 x8 + 0.042 x6 x8 + 0.217 x7 x8 + -0.749 x8^2\n",
            "\n",
            "Training Set Classification Accuracy: 76.51%\n",
            "Test Set Classification Accuracy: 61.90%\n",
            "Confusion Matrix for Test Set Classification\n",
            "[[10  0 13]\n",
            " [ 0  0  1]\n",
            " [ 2  0 16]]\n"
          ]
        }
      ],
      "source": [
        "# Grid search for optimal hyperparameters \n",
        "param_grid = {\n",
        "    'alpha': np.logspace(-4, 0.25, 10),      \n",
        "    'threshold': np.logspace(-4, 0, 10),  \n",
        "    'interval': np.linspace(0, 10, 10)  \n",
        "}\n",
        "\n",
        "#  Train model and optimize hyperparameters \n",
        "best_params, best_score = optimize_sindy_hyperparameters(\n",
        "    X_train, y_train, gsflow_train, loading_train, param_grid\n",
        ")\n",
        "\n",
        "print(\"\\nBest parameters found:\")\n",
        "print(best_params)\n",
        "print(f\"Best CV accuracy: {best_score*100:.2f}%\")\n",
        "\n",
        "# Train final model on FULL training set with best params and evaluate on the final test set\n",
        "final_optimizer = STLSQ(\n",
        "    alpha=best_params['alpha'],\n",
        "    threshold=best_params['threshold'],\n",
        "    max_iter=10000,\n",
        "    normalize_columns=True\n",
        ")\n",
        "\n",
        "# Evaluate model performance \n",
        "final_model = SINDy(optimizer=final_optimizer)\n",
        "final_model.fit(X_train_scaled, t=t_train, x_dot=y_train_scaled)\n",
        "\n",
        "# Evaluate on trainin set\n",
        "y_pred_train_scaled = final_model.predict(X_train_scaled)\n",
        "y_pred_train = scaler_y.inverse_transform(y_pred_train_scaled).flatten()\n",
        "\n",
        "# Evaluate on TEST set (previously unseen data)\n",
        "y_pred_test_scaled = final_model.predict(X_test_scaled)\n",
        "y_pred_test = scaler_y.inverse_transform(y_pred_test_scaled).flatten()\n",
        "\n",
        "# Calculate metrics on TEST set\n",
        "train_acc, train_cm = calculate_accuracy(y_pred_train, gsflow_train, loading_train, best_params['interval'])\n",
        "test_acc, test_cm = calculate_accuracy(y_pred_test, gsflow_test, loading_test, best_params['interval'])\n",
        "\n",
        "print(\"\\n=== Final Model Performance ===\")\n",
        "final_model.print()\n",
        "print(f\"\\nTraining Set Classification Accuracy: {train_acc*100:.2f}%\")\n",
        "print(f\"Test Set Classification Accuracy: {test_acc*100:.2f}%\")\n",
        "print(\"Confusion Matrix for Test Set Classification\")\n",
        "print(test_cm)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
